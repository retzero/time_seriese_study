{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XuXWJLEm2UWS"
      },
      "source": [
        "# **GCN - Lab Practice**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OCK7krJdp4o8"
      },
      "source": [
        "## **Setup**\n",
        "\n",
        "The installation of Torch and PyG is need for building and training GCN, but if you use colab, torch might be already installed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RPs-ylKS6vys",
        "outputId": "a01b4cb4-d595-49c4-9a63-dcf6da2b4d64",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.4.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: torch_geometric in /usr/local/lib/python3.10/dist-packages (2.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.10.10)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2024.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.26.4)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.2.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (4.66.5)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.15.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (4.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch_geometric) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2024.8.30)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from multidict<7.0,>=4.5->aiohttp->torch_geometric) (4.12.2)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->torch_geometric) (0.2.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch\n",
        "!pip install torch_geometric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2vkP8pA1qBE5",
        "outputId": "5804284a-c58f-41be-e334-4f0525f40fda"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch has version 2.4.1+cu121\n",
            "PyG has version 2.6.1\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "import torch_geometric\n",
        "print(\"PyTorch has version {}\".format(torch.__version__))\n",
        "print(\"PyG has version {}\".format(torch_geometric.__version__))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nwwq0nSdmsOL"
      },
      "source": [
        "# **Task 0: PyTorch Geometric (Datasets and Data)**\n",
        "\n",
        "PyTorch Geometric has two classes for storing and/or transforming graphs into tensor format. One is `torch_geometric.datasets`, which contains a variety of common graph datasets. Another is `torch_geometric.data`, which provides the data handling of graphs in PyTorch tensors.\n",
        "\n",
        "In this section, we will learn how to use `torch_geometric.datasets`\n",
        "\n",
        "## PyG Datasets\n",
        "\n",
        "The `torch_geometric.datasets` class has many common graph datasets. Here we will explore its usage through one example dataset KarateClub.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "4o-mRrROCqpD"
      },
      "outputs": [],
      "source": [
        "from torch_geometric.datasets import KarateClub\n",
        "\n",
        "dataset = KarateClub()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "zT5qca3x6XpG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a632af6-a27a-4d44-b551-feae99318879"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torch_geometric.datasets.karate.KarateClub'>\n",
            "KarateClub()\n",
            "datset has 4 classes\n",
            "datset has 34 features\n"
          ]
        }
      ],
      "source": [
        "# You will find that dataset type is based on torch_geometric.datasets\n",
        "# and please check the object class\n",
        "print(type(dataset))\n",
        "print(dataset)\n",
        "\n",
        "print(f\"datset has {dataset.num_classes} classes\")\n",
        "print(f\"datset has {dataset.num_features} features\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "iG8fzodgFF5M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a984cd10-0395-418d-ef6c-8cf344bc41a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data(x=[34, 34], edge_index=[2, 156], y=[34], train_mask=[34])\n"
          ]
        }
      ],
      "source": [
        "print(dataset[0])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "graph = dataset[0]"
      ],
      "metadata": {
        "id": "KDLqaepxDjgU"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w1cgKWncKNTF"
      },
      "source": [
        "## PyG Graph Data\n",
        "Graph data generally has\n",
        "\n",
        "||Meaning|Tensor shape|\n",
        "|-----|-----|-----|\n",
        "|graph.x|node feature|[ *N x F* ]|\n",
        "|graph.edge_index|edge information|[ *2 x E* ]|\n",
        "|graph.y|node's label|[ *N* ]|\n",
        "\n",
        "\n",
        "**You can check data.x , data.edge_index, data.y in the following codes**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OIw_52FHUexg",
        "outputId": "57ebee08-e71c-4fea-8a2c-d962bd0ce2ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Graph(Dataset index 0) has node feature \n",
            "tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 1.]])\n",
            "Node featureshas tensor shape \n",
            "torch.Size([34, 34])\n"
          ]
        }
      ],
      "source": [
        "print(f\"Graph(Dataset index 0) has node feature \\n{graph.x}\")\n",
        "print(f\"Node featureshas tensor shape \\n{graph.x.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SPuK5ErNVlpo",
        "outputId": "3749836e-6270-4247-f6e5-c20e1512b22a",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Graph(Dataset index 0) has edge_index \n",
            "tensor([[ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1,  1,\n",
            "          1,  1,  1,  1,  1,  1,  1,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  3,\n",
            "          3,  3,  3,  3,  3,  4,  4,  4,  5,  5,  5,  5,  6,  6,  6,  6,  7,  7,\n",
            "          7,  7,  8,  8,  8,  8,  8,  9,  9, 10, 10, 10, 11, 12, 12, 13, 13, 13,\n",
            "         13, 13, 14, 14, 15, 15, 16, 16, 17, 17, 18, 18, 19, 19, 19, 20, 20, 21,\n",
            "         21, 22, 22, 23, 23, 23, 23, 23, 24, 24, 24, 25, 25, 25, 26, 26, 27, 27,\n",
            "         27, 27, 28, 28, 28, 29, 29, 29, 29, 30, 30, 30, 30, 31, 31, 31, 31, 31,\n",
            "         31, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 33, 33, 33, 33, 33,\n",
            "         33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33],\n",
            "        [ 1,  2,  3,  4,  5,  6,  7,  8, 10, 11, 12, 13, 17, 19, 21, 31,  0,  2,\n",
            "          3,  7, 13, 17, 19, 21, 30,  0,  1,  3,  7,  8,  9, 13, 27, 28, 32,  0,\n",
            "          1,  2,  7, 12, 13,  0,  6, 10,  0,  6, 10, 16,  0,  4,  5, 16,  0,  1,\n",
            "          2,  3,  0,  2, 30, 32, 33,  2, 33,  0,  4,  5,  0,  0,  3,  0,  1,  2,\n",
            "          3, 33, 32, 33, 32, 33,  5,  6,  0,  1, 32, 33,  0,  1, 33, 32, 33,  0,\n",
            "          1, 32, 33, 25, 27, 29, 32, 33, 25, 27, 31, 23, 24, 31, 29, 33,  2, 23,\n",
            "         24, 33,  2, 31, 33, 23, 26, 32, 33,  1,  8, 32, 33,  0, 24, 25, 28, 32,\n",
            "         33,  2,  8, 14, 15, 18, 20, 22, 23, 29, 30, 31, 33,  8,  9, 13, 14, 15,\n",
            "         18, 19, 20, 22, 23, 26, 27, 28, 29, 30, 31, 32]])\n",
            "Edge_index has tensor shape \n",
            "torch.Size([2, 156])\n"
          ]
        }
      ],
      "source": [
        "print(f\"Graph(Dataset index 0) has edge_index \\n{graph.edge_index}\")\n",
        "print(f\"Edge_index has tensor shape \\n{graph.edge_index.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3FdtCVzrVnfi",
        "outputId": "b9991a8c-9865-4ff8-b0c2-6cb58d056e34"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Graph(Dataset index 0) has node labels \n",
            "tensor([1, 1, 1, 1, 3, 3, 3, 1, 0, 1, 3, 1, 1, 1, 0, 0, 3, 1, 0, 1, 0, 1, 0, 0,\n",
            "        2, 2, 0, 0, 2, 0, 0, 2, 0, 0])\n",
            "Graph label has tensor shape \n",
            "torch.Size([34])\n"
          ]
        }
      ],
      "source": [
        "print(f\"Graph(Dataset index 0) has node labels \\n{graph.y}\")\n",
        "print(f\"Graph label has tensor shape \\n{graph.y.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9DP_yEQZ0NVW"
      },
      "source": [
        "# **Task1: Node Classification with Matrix Multiplication**\n",
        "\n",
        "In this section to better understand the GCN matrix calculation, we'll do a quick exercise with matrix operations. Then we will apply it to the task of node classification.\n",
        "\n",
        "\n",
        "It is only for to get the basic idea of GNN(what's going on inside the GNN model), so elaborated training and testing is omitted.\n",
        "\n",
        "In the later part, we will create a full model using the simpler, and already implemented pyG module GCNConv.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "98vkp32kPgpo"
      },
      "source": [
        "In this time, we will use **Cora dataset**.\n",
        "\n",
        "The Cora dataset is a citation graph where nodes represent papers and edges represent citations between pairs of papers. The task involved is document classification, where the goal is to classify each paper into one of seven categories, i.e., a multi-class classification problem with seven classes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "p9cZ2hqsNdt8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c18a453-407e-443c-e74c-a78ab38d34f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ],
      "source": [
        "from torch_geometric.datasets import Planetoid\n",
        "root_dir = os.getcwd()\n",
        "dataset = Planetoid(root = root_dir, name = \"Cora\")\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6UyE7lI1QM8m",
        "outputId": "4f1198b3-bc18-4adf-d818-6899d1f59e31"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data(x=[2708, 1433], edge_index=[2, 10556], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708])\n"
          ]
        }
      ],
      "source": [
        "# You can confirm that Cora is composed of a single large graph.\n",
        "data = dataset[0]\n",
        "data = data.to(device)\n",
        "print(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Y9nk1rxPjxm"
      },
      "source": [
        "### **GCN Convolutional Networks**\n",
        "\n",
        "### **$ H^{(l+1)} = \\sigma(\\tilde{D}^{-1/2} \\tilde{A} \\tilde{D}^{-1/2} H^{(l)} W^{(l)})  \\quad where \\quad  \\tilde{A} = A + I,  \\; \\tilde{D}_{ii} = \\sum_j{\\tilde{A}_{ij}}$**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "i-qYRlqOTSKq"
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as F\n",
        "from torch import optim\n",
        "from tqdm import tqdm\n",
        "\n",
        "class matGCNLayer(nn.Module):\n",
        "    def __init__(self, in_features, out_features):\n",
        "        super(matGCNLayer, self).__init__()\n",
        "\n",
        "        # self.Linear takes role of parameter W\n",
        "        self.linear = nn.Linear(in_features, out_features)\n",
        "\n",
        "    # Adjacency matrix normalization\n",
        "    def forward(self, x, adj):\n",
        "        ############# Your code here ############\n",
        "        # Add self-loops and you must specify device in torch.eye\n",
        "        adj_hat = adj + torch.eye(adj.size(0),device=device)\n",
        "\n",
        "        # Degree matrix\n",
        "        degree = torch.diag(torch.sum(adj_hat, dim=1))\n",
        "\n",
        "        # D_tilde^(-1/2)\n",
        "        degree_inv_sqrt = torch.inverse(torch.sqrt(degree))\n",
        "\n",
        "        # D_tilde^(-1/2)* A_hat * D_tilde^(-1/2)\n",
        "        # you can use torch.mm to multiply torch.mm(input,mat2)\n",
        "        # If input is a [n, m] tensor, mat2 is a [m, p] tensor, out will be a [n, p] tensor\n",
        "        adj_norm = torch.mm(degree_inv_sqrt, torch.mm(adj_hat, degree_inv_sqrt))\n",
        "\n",
        "        # Graph Convolution: A_hat * X * W\n",
        "        out = self.linear(torch.mm(adj_norm, x))\n",
        "        #########################################\n",
        "        return out\n",
        "\n",
        "class matGCN(nn.Module):\n",
        "    def __init__(self, n_features, hidden_size, n_classes):\n",
        "        super(matGCN, self).__init__()\n",
        "\n",
        "        self.gc1 = matGCNLayer(n_features, hidden_size)\n",
        "        self.gc2 = matGCNLayer(hidden_size, n_classes)\n",
        "\n",
        "        self.softmax = nn.LogSoftmax()\n",
        "\n",
        "    def forward(self, x, adj):\n",
        "        ############# Your code here ############\n",
        "        # First layer\n",
        "        # We use F.relu here instead of sigmoid\n",
        "        x = F.relu(self.gc1(x, adj))\n",
        "\n",
        "        # Second layer\n",
        "        out = self.gc2(x, adj)\n",
        "\n",
        "        # predict using softmax\n",
        "        pred = self.softmax(out)\n",
        "        #########################################\n",
        "        return pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "UDi9OZG-TXop"
      },
      "outputs": [],
      "source": [
        "def train(model, graph, adj, epochs=20, lr=0.01):\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "    # Set the model to be trained\n",
        "    model.train()\n",
        "\n",
        "    labels = graph.y\n",
        "\n",
        "    for epoch in tqdm(range(epochs)):\n",
        "        ############# Your code here ############\n",
        "        # Clear gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Perform a single forward pass\n",
        "        output = model(graph.x, adj)\n",
        "\n",
        "        # Compute the loss solely based on the training nodes\n",
        "        # You should use datasets for train by masking the ouput and labels\n",
        "        loss = loss_fn(output[graph.train_mask], labels[graph.train_mask])\n",
        "\n",
        "        # Derive gradients\n",
        "        loss.backward()\n",
        "\n",
        "        # Update parameters based on gradients\n",
        "        optimizer.step()\n",
        "\n",
        "        #########################################\n",
        "\n",
        "        print(f'Epoch {epoch}, Loss: {loss.item()}')\n",
        "\n",
        "def test(model, graph, adj):\n",
        "    # Set the model to be evaluated\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        ############# Your code here ############\n",
        "        # Perform a single forward pass\n",
        "        out = model(graph.x, adj)\n",
        "\n",
        "        # Prediction would be the class with highest probability(you can use argmax)\n",
        "        pred = out.argmax(dim=1)\n",
        "\n",
        "        # Count the number of correct prediction against ground truth\n",
        "        test_correct = torch.sum(pred[graph.test_mask] == graph.y[graph.test_mask])\n",
        "\n",
        "        # Derive ratio of correct predictions\n",
        "        test_acc = test_correct / int(graph.test_mask.sum())\n",
        "        #########################################\n",
        "\n",
        "    print(f'Accuracy: {test_acc:.4f}')\n",
        "    return test_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "qEquOAK9pZ3d"
      },
      "outputs": [],
      "source": [
        "from torch_geometric.utils import to_dense_adj\n",
        "\n",
        "# Build the model and adjacency matrix\n",
        "model = matGCN(n_features=data.num_features, hidden_size=16, n_classes=7).to(device)\n",
        "\n",
        "# By utilizing to_dense_adj, we can construct adjacency matrix easily\n",
        "adj = to_dense_adj(data.edge_index).squeeze()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LBiWcVMYuPQo",
        "outputId": "b4dee6cc-8875-4508-e7dd-c33b7d7d23c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/20 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1553: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "  5%|▌         | 1/20 [00:12<03:52, 12.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 1.9604758024215698\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 2/20 [00:18<02:35,  8.63s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 1.906951904296875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 15%|█▌        | 3/20 [00:24<02:06,  7.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2, Loss: 1.8220713138580322\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 4/20 [00:29<01:45,  6.60s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3, Loss: 1.7341594696044922\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 25%|██▌       | 5/20 [00:35<01:34,  6.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4, Loss: 1.641500473022461\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 6/20 [00:40<01:22,  5.92s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5, Loss: 1.5400410890579224\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 35%|███▌      | 7/20 [00:45<01:11,  5.53s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6, Loss: 1.4325940608978271\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 8/20 [00:51<01:08,  5.71s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7, Loss: 1.3219056129455566\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 45%|████▌     | 9/20 [00:56<00:59,  5.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8, Loss: 1.2093298435211182\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 10/20 [01:01<00:55,  5.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9, Loss: 1.0967273712158203\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 55%|█████▌    | 11/20 [01:07<00:48,  5.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10, Loss: 0.9857112169265747\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 12/20 [01:11<00:41,  5.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11, Loss: 0.8776938319206238\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 65%|██████▌   | 13/20 [01:18<00:38,  5.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12, Loss: 0.7740538716316223\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|███████   | 14/20 [01:22<00:31,  5.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13, Loss: 0.6762350797653198\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 75%|███████▌  | 15/20 [01:28<00:27,  5.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14, Loss: 0.5853884220123291\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 16/20 [01:33<00:21,  5.34s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15, Loss: 0.5025535821914673\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 85%|████████▌ | 17/20 [01:39<00:15,  5.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16, Loss: 0.4282490909099579\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 18/20 [01:45<00:11,  5.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17, Loss: 0.3626924455165863\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 95%|█████████▌| 19/20 [01:50<00:05,  5.34s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18, Loss: 0.30567166209220886\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [01:55<00:00,  5.80s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19, Loss: 0.25674518942832947\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Let's just see the training process simply\n",
        "train(model, data, adj)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WV-qJ63LA2Py",
        "outputId": "a67dbd82-4c0a-47aa-bf04-57d574969cdd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.7880\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.7880)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "test(model,data,adj)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tt8zDa7oBbEA"
      },
      "source": [
        "# **Task 2: Node Classification with GCNConv**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O4CcOUEoInjD"
      },
      "source": [
        "## Load and Split the Dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "-DCtgcHpGIpd"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torch_geometric.nn import GCNConv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OgUA815bNJ8w"
      },
      "source": [
        "## GCN Model\n",
        "\n",
        "Now we will construct our GCN model!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JWIx22OR7fdp"
      },
      "source": [
        "## Why we use torch.nn.ModuleList?\n",
        "\n",
        "We need to let PyTorch know that the modules exist by putting them in nn.ModuleList.\n",
        "If we don't put them in nn.ModuleList and only put them in the Python list, PyTorch won't know they exist.\n",
        "In this case, you will get an error like \"your model has no parameter\" when declaring optimzier and passing parameters to model.parameter().\n",
        "So if you keep your modules in a Python list, make sure to wrap them in nn.ModuleList at the end.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "IgspXTYpNJLA"
      },
      "outputs": [],
      "source": [
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim, dropout,\n",
        "                return_embeds=False):\n",
        "        super(GCN, self).__init__()\n",
        "\n",
        "        self.convs = None\n",
        "        self.softmax = None\n",
        "\n",
        "        ############# Your code here ############\n",
        "        # GCNConv() is used to represent a GCN layer\n",
        "        # Convolutional layers with input layer, 2 hidden layers, and output layer\n",
        "\n",
        "        self.conv1 = GCNConv(input_dim, hidden_dim)\n",
        "        self.hidden1 = GCNConv(hidden_dim, hidden_dim)\n",
        "        self.hidden2 = GCNConv(hidden_dim, hidden_dim)\n",
        "        self.conv2 = GCNConv(hidden_dim, output_dim)\n",
        "\n",
        "        # To manage a list of modules, torch.nn.ModuleList() is recommended\n",
        "        # Fill in the parameter of torch.nn.ModuleList() --> torch.nn.ModuleList([layer_1] + [layer_2] + ... + [layer_n])\n",
        "        self.convs = torch.nn.ModuleList([self.conv1] + [self.hidden1] + [self.hidden2] + [self.conv2])\n",
        "\n",
        "        #########################################\n",
        "\n",
        "        # We define softmax to pass the last layer output through\n",
        "        self.softmax = torch.nn.LogSoftmax()\n",
        "\n",
        "        # Probability of an element getting zeroed\n",
        "        self.dropout = dropout\n",
        "\n",
        "        # Skip classification layer and return node embeddings\n",
        "        self.return_embeds = return_embeds\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        for conv in self.convs:\n",
        "            conv.reset_parameters()\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        out = None\n",
        "\n",
        "        ############# Your code here ############\n",
        "        # Each layer output is put into the F.relu,\n",
        "        # and during training process, prevent overfitting by using F.dropout\n",
        "\n",
        "        for conv in self.convs[:-1]:\n",
        "            # Make the input to pass a layer and activation function\n",
        "            x1 = F.relu(conv(x,edge_index))\n",
        "            if self.training:\n",
        "                # Dropout with probability p : you can use self.dropout as parameter p\n",
        "                x1 = F.dropout(x1, p =self.dropout)\n",
        "            x = x1\n",
        "        # The last layer output doesn't pass the activation function and dropout layer\n",
        "        x = self.convs[-1](x,edge_index)\n",
        "        out = x if self.return_embeds else self.softmax(x)\n",
        "        #########################################\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_mask = data.train_mask\n",
        "val_mask = data.val_mask\n",
        "test_mask = data.test_mask"
      ],
      "metadata": {
        "id": "-nl1gbTHD4jy"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "FF1hnHUhO81e"
      },
      "outputs": [],
      "source": [
        "def train(model, data, optimizer, loss_fn):\n",
        "\n",
        "    model.train()\n",
        "    loss = 0\n",
        "\n",
        "    ############# Your code here ############\n",
        "    # Clear gradients\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Perform a single forward pass\n",
        "    output = model(data.x, data.edge_index)\n",
        "\n",
        "    # Compute the loss solely based on the training nodes\n",
        "    # Predictions & labels are specified as output[train_mask] & data.y[train_mask], respectively\n",
        "    loss = loss_fn(output[train_mask], data.y[train_mask])\n",
        "\n",
        "    # Derive gradients\n",
        "    loss.backward()\n",
        "\n",
        "    # Update parameters based on gradients\n",
        "    optimizer.step()\n",
        "    #########################################\n",
        "    return loss.item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "aJdlrJQhPBsK"
      },
      "outputs": [],
      "source": [
        "def test(model,data, mode):\n",
        "    # TODO: Implement a function that tests the model by\n",
        "    model.eval()\n",
        "\n",
        "    out = None\n",
        "\n",
        "    if mode == \"val\":\n",
        "        mask = val_mask\n",
        "    elif mode == \"test\":\n",
        "        mask = test_mask\n",
        "    else: assert False, \"mode should be 'val' or 'test'\"\n",
        "\n",
        "    with torch.no_grad():\n",
        "        ############# Your code here ############\n",
        "        # Perform a single forward pass\n",
        "        out = model(data.x, data.edge_index)\n",
        "\n",
        "        # Prediction would be the class with highest probability(you can use argmax)\n",
        "        pred = out.argmax(dim=1)\n",
        "\n",
        "        # Count the number of correct prediction against ground truth\n",
        "        test_correct = torch.sum(pred[mask] == data.y[mask])\n",
        "\n",
        "        # Derive ratio of correct predictions\n",
        "        test_acc = test_correct / int(mask.sum())\n",
        "        #########################################\n",
        "\n",
        "    return test_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o7F46xkuLiOL",
        "outputId": "64b7275f-6849-4c9e-976a-5020e4789250"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'device': 'cpu', 'hidden_dim': 256, 'dropout': 0.2, 'lr': 0.001, 'epochs': 50}"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "args = {\n",
        "    'device': device,\n",
        "    'hidden_dim': 256,\n",
        "    'dropout': 0.2,\n",
        "    'lr': 0.001,\n",
        "    'epochs': 50,\n",
        "}\n",
        "args"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "dT8RyM2cPGxM"
      },
      "outputs": [],
      "source": [
        "model = GCN(data.num_features, args['hidden_dim'], dataset.num_classes, args['dropout']).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "qd5O5cnPPdVF",
        "outputId": "e179a9e7-4889-4cf0-d596-7d496fa95799"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1553: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 05, Loss: 1.7954, Val_acc: 68.4000015258789%\n",
            "Epoch: 10, Loss: 1.3508, Val_acc: 78.0%\n",
            "Epoch: 15, Loss: 0.6127, Val_acc: 79.79999542236328%\n",
            "Epoch: 20, Loss: 0.1874, Val_acc: 78.79999542236328%\n",
            "Epoch: 25, Loss: 0.0572, Val_acc: 77.80000305175781%\n",
            "Epoch: 30, Loss: 0.0246, Val_acc: 76.80000305175781%\n",
            "Epoch: 35, Loss: 0.0132, Val_acc: 76.4000015258789%\n",
            "Epoch: 40, Loss: 0.0073, Val_acc: 75.80000305175781%\n",
            "Epoch: 45, Loss: 0.0041, Val_acc: 76.0%\n",
            "Epoch: 50, Loss: 0.0011, Val_acc: 76.5999984741211%\n"
          ]
        }
      ],
      "source": [
        "import copy\n",
        "\n",
        "# reset the parameters to initial random value\n",
        "model.reset_parameters()\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=args['lr'])\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "best_model = None\n",
        "best_valid_acc = 0\n",
        "\n",
        "for epoch in range(1, 1 + args[\"epochs\"]):\n",
        "    loss = train(model, data, optimizer, loss_fn)\n",
        "    if epoch % 5 == 0:\n",
        "        val_acc = test(model, data, \"val\")\n",
        "        print(f'Epoch: {epoch:02d}, '\n",
        "        f'Loss: {loss:.4f}, '\n",
        "        f'Val_acc: {100*val_acc}%')\n",
        "\n",
        "        if best_valid_acc < val_acc:\n",
        "            best_valid_acc = val_acc\n",
        "            best_model = copy.deepcopy(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EqcextqOL2FX",
        "outputId": "aeba93d1-ad3b-4de9-84a5-ffafde79d1d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best model: Test: 81.20%\n"
          ]
        }
      ],
      "source": [
        "best_result = test(best_model, data, \"test\")\n",
        "print(f'Best model: '\n",
        "    f'Test: {100 * best_result:.2f}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **(Optional) Task 3: Implication of to_dense_adj on 2 dimension**\n",
        "## **to_dense_adj**\n",
        "\n",
        "We can easily use to_dense_adj defined in torch_geometric when transforming edge_index to adjacency matrix. If we have a good understanding of the relationship between edge_index and adj matrix, can we create our own function similarily? Of course, ours is a simplified version, no batch, and can only be used for cora datasets where max_node_num(node_num) is already known.\n",
        "\n",
        "We could create the adj matrix by simply putting a 1 in the index corresponding to each pair of edge_index, but let's use torch_geometric.scatter to calculate in a more computationally efficient way.\n",
        "\n",
        "https://pytorch-geometric.readthedocs.io/en/2.3.1/modules/utils.html#torch_geometric.utils.to_dense_adj\n",
        "\n",
        "\n",
        "## **torch_geometric.utils.scatter**\n",
        "\n",
        "    def scatter(src: Tensor, index: Tensor, dim: int = 0,\n",
        "                dim_size: Optional[int] = None, reduce: str = 'sum') -> Tensor:\n",
        "\n",
        "As torch package has scatter, torch_geometric has scatter function.\n",
        "The scatter function in PyG aggregates a tensor of data according to given indices. It supports aggregation methods like sum, mean, max, and min, making it useful for summarizing node or edge features in graph data.\n",
        "\n",
        "https://pytorch-geometric.readthedocs.io/en/latest/modules/utils.html#torch_geometric.utils.scatter\n",
        "\n",
        "***Be sure to read this page before going to next step:*** https://pytorch-scatter.readthedocs.io/en/latest/functions/scatter.html\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "shRkR1VOTBC4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "jCtapItOXefp"
      },
      "outputs": [],
      "source": [
        "from torch_geometric.utils import scatter\n",
        "\n",
        "def to_dense_adj(edge_index, num_nodes):\n",
        "    # adjacency matrix size\n",
        "    size = [num_nodes, num_nodes]\n",
        "\n",
        "    # Row index(idx1) & column index(idx2)\n",
        "    idx1 = edge_index[0]\n",
        "    idx2 = edge_index[1]\n",
        "\n",
        "    # value 1s to be scattered\n",
        "    src = torch.ones(edge_index.size(1), device=edge_index.device)\n",
        "\n",
        "    ############# Your code here ############\n",
        "    # Output dimension of scatter function\n",
        "    flattened_size = num_nodes * num_nodes\n",
        "\n",
        "    # Parameter index of scatter function\n",
        "    idx = idx1 * num_nodes + idx2\n",
        "\n",
        "    # Scatter\n",
        "    flatten_adj = scatter(src, idx, dim=0, dim_size=flattened_size, reduce='sum')\n",
        "\n",
        "    # Resize [num_nodes * num_nodes] to [num_nodes, num_nodes]\n",
        "    adj = flatten_adj.view(size)\n",
        "    #########################################\n",
        "    return adj"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9xC74QZKRIve"
      },
      "execution_count": 37,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}